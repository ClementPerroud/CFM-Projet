{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:13.695522Z",
     "iopub.status.busy": "2023-03-14T14:59:13.694498Z",
     "iopub.status.idle": "2023-03-14T14:59:13.703264Z",
     "shell.execute_reply": "2023-03-14T14:59:13.702057Z",
     "shell.execute_reply.started": "2023-03-14T14:59:13.695475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 18:35:01.485898: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 18:35:05.454425: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/clement/miniconda3/envs/tf/lib/\n",
      "2023-03-15 18:35:05.454948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/clement/miniconda3/envs/tf/lib/\n",
      "2023-03-15 18:35:05.454963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from utils import *\n",
    "from layers import *\n",
    "from AdvASLTM import *\n",
    "import keras_tuner\n",
    "from sklearn.preprocessing import RobustScaler, QuantileTransformer, PowerTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:13.704466Z",
     "iopub.status.busy": "2023-03-14T14:59:13.704193Z",
     "iopub.status.idle": "2023-03-14T14:59:28.638245Z",
     "shell.execute_reply": "2023-03-14T14:59:28.637397Z",
     "shell.execute_reply.started": "2023-03-14T14:59:13.704435Z"
    }
   },
   "outputs": [],
   "source": [
    "nrows = 150000\n",
    "x_train_df = pd.read_csv(\"input_training.csv\", index_col=\"ID\")\n",
    "y_train_df = pd.read_csv(\"output_training_gmEd6Zt.csv\", index_col=\"ID\")\n",
    "x_test_df = pd.read_csv(\"input_test.csv\", index_col=\"ID\")\n",
    "\n",
    "if nrows is not None:\n",
    "    x_train_df = x_train_df.iloc[-nrows:]\n",
    "    y_train_df = y_train_df.iloc[-nrows:]\n",
    "\n",
    "y_train_df[\"reod\"] = y_train_df[\"reod\"] + 1\n",
    "\n",
    "train_df = x_train_df.join(y_train_df).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_filter = re.compile(\"r[0-9]+\")\n",
    "features_columns = list(filter(r_filter.match, train_df.columns)) # + [\"week_day\", \"total_r0-52\"]\n",
    "preprocessed_features_columns = [f\"preprocessed_{col}\" for col in features_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "1 - Dealing with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:28.640750Z",
     "iopub.status.busy": "2023-03-14T14:59:28.640363Z",
     "iopub.status.idle": "2023-03-14T14:59:28.665681Z",
     "shell.execute_reply": "2023-03-14T14:59:28.664780Z",
     "shell.execute_reply.started": "2023-03-14T14:59:28.640721Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check distribution of label on row that contain NaN\n",
    "train_df.loc[(train_df.isna().sum(axis=1) > 10), \"reod\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:28.667039Z",
     "iopub.status.busy": "2023-03-14T14:59:28.666764Z",
     "iopub.status.idle": "2023-03-14T14:59:28.814444Z",
     "shell.execute_reply": "2023-03-14T14:59:28.813555Z",
     "shell.execute_reply.started": "2023-03-14T14:59:28.667015Z"
    }
   },
   "outputs": [],
   "source": [
    "#As NaNs are also present in the test dataset, I cannot delete. I chose to replace them with zeros\n",
    "train_df.replace(np.nan, 0, inplace = True)\n",
    "x_test_df.replace(np.nan, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:28.816134Z",
     "iopub.status.busy": "2023-03-14T14:59:28.815858Z",
     "iopub.status.idle": "2023-03-14T14:59:30.477004Z",
     "shell.execute_reply": "2023-03-14T14:59:30.475988Z",
     "shell.execute_reply.started": "2023-03-14T14:59:28.816108Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"total_r0-52\"] = list(map(\n",
    "    composed_bps_returns,\n",
    "    train_df[list(filter(r_filter.match, train_df.columns))].to_numpy()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:30.478480Z",
     "iopub.status.busy": "2023-03-14T14:59:30.478211Z",
     "iopub.status.idle": "2023-03-14T14:59:30.483951Z",
     "shell.execute_reply": "2023-03-14T14:59:30.482616Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.478441Z"
    }
   },
   "outputs": [],
   "source": [
    "#plot_matrix(train_df, \"day\", \"equity\", \"total_r0-52\", lambda x : list(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add features\n",
    "1 - Time features (day of the week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:30.485704Z",
     "iopub.status.busy": "2023-03-14T14:59:30.485163Z",
     "iopub.status.idle": "2023-03-14T14:59:30.522980Z",
     "shell.execute_reply": "2023-03-14T14:59:30.521949Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.485679Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df[\"week_day\"] = train_df[\"day\"].apply(lambda x : x % 5)\n",
    "#plot_matrix(train_df,\"week_day\", \"equity\", \"total_r0-52\", lambda x : list(x)[0], x_lim=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T14:59:30.532784Z",
     "iopub.status.busy": "2023-03-14T14:59:30.532534Z",
     "iopub.status.idle": "2023-03-14T14:59:30.857399Z",
     "shell.execute_reply": "2023-03-14T14:59:30.855586Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.532760Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.sort_values(by=\"day\", inplace= True) # Sort by day to get as close as possible from the test dataset conditions with my validation dataset\n",
    "\n",
    "train_ratio = 0.8\n",
    "train_limit = int(train_ratio*len(train_df))\n",
    "\n",
    "X_train = train_df[features_columns].iloc[:train_limit].to_numpy()\n",
    "y_train = tf.keras.utils.to_categorical(train_df['reod'].iloc[:train_limit], num_classes=3)\n",
    "\n",
    "X_validation = train_df[features_columns].iloc[train_limit:].to_numpy()\n",
    "y_validation = tf.keras.utils.to_categorical(train_df['reod'].iloc[train_limit:], num_classes=3)\n",
    "\n",
    "X_test = x_test_df[features_columns].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T15:02:32.474893Z",
     "iopub.status.busy": "2023-03-14T15:02:32.474531Z",
     "iopub.status.idle": "2023-03-14T15:02:32.493896Z",
     "shell.execute_reply": "2023-03-14T15:02:32.492667Z",
     "shell.execute_reply.started": "2023-03-14T15:02:32.474867Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def reccurent_layer(type, *args, **kwargs):\n",
    "    if type == \"LSTM\":\n",
    "        return tf.keras.layers.LSTM(*args, **kwargs)\n",
    "    elif type == \"GRU\":\n",
    "        return tf.keras.layers.GRU(*args, **kwargs)\n",
    "    raise ValueError(f\"Type args is wrong : '{type}' while it should be 'LSTM' or 'GRU'\")\n",
    "\n",
    "def optimizer(type, *args, **kwargs):\n",
    "    if type == \"adam\":\n",
    "        return tf.keras.optimizers.Adam(*args, **kwargs)\n",
    "    elif type == \"rmsprop\":\n",
    "        return tf.keras.optimizers.RMSprop(*args, **kwargs)\n",
    "    raise ValueError(f\"Type args is wrong : '{type}' while it should be 'adam' or 'rmsprop'\")\n",
    "\n",
    "\n",
    "class MyHyperModel(keras_tuner.HyperModel):\n",
    "    def __init__(self, X_train, y_train, X_validation, y_validation, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.X_train = X_train\n",
    "        self.X_validation = X_validation\n",
    "        self.y_train = y_train\n",
    "        self.y_validation = y_validation\n",
    "\n",
    "        self.tranformer_robust = RobustScaler(unit_variance = True, with_centering= True).fit(X_train)\n",
    "        self.tranformer_quantile = QuantileTransformer(output_distribution='normal').fit(X_train)\n",
    "        self.tranformer_power = PowerTransformer(method='yeo-johnson', standardize=True).fit(X_train)\n",
    "\n",
    "        self.X_train_robust = self.tranformer_robust.transform(X_train)[:, :, np.newaxis]\n",
    "        self.X_train_quantile = self.tranformer_quantile.transform(X_train)[:, :, np.newaxis]\n",
    "        self.X_train_power = self.tranformer_power.transform(X_train)[:, :, np.newaxis]\n",
    "        self.X_validation_robust = self.tranformer_robust.transform(X_validation)[:, :, np.newaxis]\n",
    "        self.X_validation_quantile = self.tranformer_quantile.transform(X_validation)[:, :, np.newaxis]\n",
    "        self.X_validation_power = self.tranformer_power.transform(X_validation)[:, :, np.newaxis]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def build(self, hp):\n",
    "        nb_reccurrent_layers = hp.Int(\"nb_reccurrent_layers\", min_value = 1, max_value = 4, step=1)\n",
    "        reccurrent_unit = hp.Int(\"reccurrent_unit\", min_value = 4, max_value = 512, sampling = \"log\")\n",
    "        reccurrent_dropout = hp.Float(\"reccurrent_dropout\", min_value = 0, max_value = 0.3, sampling = \"linear\")\n",
    "        reccurent_type = hp.Choice(\"reccurent_type\", [\"LSTM\", \"GRU\"])\n",
    "        attention_layer = hp.Boolean(\"attention_layer\")\n",
    "        learning_rate = hp.Float(\"learning_rate\",  1E-5, 1E-2, sampling = \"log\")\n",
    "        opt_type = hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\"])\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for i in range(nb_reccurrent_layers - 1):\n",
    "            layers.append(reccurent_layer(reccurent_type, reccurrent_unit, dropout = reccurrent_dropout, return_sequences = True))\n",
    "        \n",
    "        if attention_layer:layers.append(AttentionLayer(reccurrent_unit, dropout = reccurrent_dropout))\n",
    "        else:layers.append(reccurent_layer(reccurent_type, reccurrent_unit, dropout = reccurrent_dropout, return_sequences = False))\n",
    "\n",
    "        \n",
    "        layers.append(tf.keras.layers.Dense(3, activation= \"softmax\"))\n",
    "\n",
    "        model = tf.keras.models.Sequential(layers)\n",
    "        \n",
    "        model.compile(\n",
    "            optimizer = optimizer(opt_type, learning_rate = learning_rate),\n",
    "            loss = hp.Choice(\"loss\", [\"categorical_crossentropy\", \"categorical_hinge\"]), \n",
    "            metrics=[\"acc\"]\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        preprocessing_method = hp.Choice(\"preprocess\", [\"robust_scale\", \"power_transform\", \"quantile_transform\", \"none\"])\n",
    "        if preprocessing_method == \"robust_scale\":\n",
    "            X_train = self.X_train_robust\n",
    "            X_validation = self.X_validation_robust\n",
    "        elif preprocessing_method == \"quantile_transform\":\n",
    "            X_train = self.X_train_quantile\n",
    "            X_validation = self.X_validation_quantile\n",
    "        elif preprocessing_method == \"power_transform\":\n",
    "            X_train = self.X_train_power\n",
    "            X_validation = self.X_validation_power\n",
    "        else:\n",
    "            raise ValueError(f\"Preprocessing method is invalid : '{preprocessing_method}'\")\n",
    "            \n",
    "        seq_len = hp.Int(\"seq_len\", min_value = 5, max_value = X_train.shape[1], step=1)\n",
    "\n",
    "        \n",
    "        return model.fit(\n",
    "            X_train[:, -seq_len:, :], self.y_train,\n",
    "            validation_data = (X_validation[:, -seq_len:, :], self.y_validation),\n",
    "            *args, **kwargs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T15:02:53.619580Z",
     "iopub.status.busy": "2023-03-14T15:02:53.619243Z",
     "iopub.status.idle": "2023-03-14T15:03:01.936779Z",
     "shell.execute_reply": "2023-03-14T15:03:01.935843Z",
     "shell.execute_reply.started": "2023-03-14T15:02:53.619554Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner = keras_tuner.Hyperband(\n",
    "    MyHyperModel(X_train, y_train, X_validation, y_validation),\n",
    "    objective=\"val_acc\",\n",
    "    max_epochs=30,\n",
    "    factor=2,\n",
    "    hyperband_iterations=1,\n",
    "    directory=\"keras_tuner_checkpoints\",\n",
    "    project_name=\"tune_hypermodel2\",\n",
    ")\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T15:03:02.681314Z",
     "iopub.status.busy": "2023-03-14T15:03:02.680329Z",
     "iopub.status.idle": "2023-03-14T15:52:07.970977Z",
     "shell.execute_reply": "2023-03-14T15:52:07.969390Z",
     "shell.execute_reply.started": "2023-03-14T15:03:02.681284Z"
    }
   },
   "outputs": [],
   "source": [
    "tuner.search(callbacks = [stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-14T14:59:30.885816Z",
     "iopub.status.idle": "2023-03-14T14:59:30.886153Z",
     "shell.execute_reply": "2023-03-14T14:59:30.886004Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.885987Z"
    }
   },
   "outputs": [],
   "source": [
    "#import shutil\n",
    "#shutil.rmtree('/notebooks/keras_tuner_checkpoints/tune_hypermodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-14T14:59:30.887119Z",
     "iopub.status.idle": "2023-03-14T14:59:30.887427Z",
     "shell.execute_reply": "2023-03-14T14:59:30.887293Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.887277Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_best_hp = { key:[] for key in tuner.get_best_hyperparameters()[0].values.keys()}\n",
    "list_best_hp = tuner.get_best_hyperparameters(num_trials= 10)\n",
    "for i in range(10):\n",
    "    for key in dict_best_hp.keys():\n",
    "        dict_best_hp[key].append(list_best_hp[i].values[key] if key in list_best_hp[i].values.keys() else None)\n",
    "pd.DataFrame(dict_best_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tranformer_robust = RobustScaler(unit_variance = True, with_centering= True).fit(X_train)\n",
    "\n",
    "X_train_robust = tranformer_robust.transform(X_train)[:, :, np.newaxis]\n",
    "X_validation_robust = tranformer_robust.transform(X_validation)[:, :, np.newaxis]\n",
    "\n",
    "\n",
    "seq_len = 40\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-14T16:45:34.132556Z",
     "iopub.status.busy": "2023-03-14T16:45:34.132172Z",
     "iopub.status.idle": "2023-03-14T16:46:43.431643Z",
     "shell.execute_reply": "2023-03-14T16:46:43.430398Z",
     "shell.execute_reply.started": "2023-03-14T16:45:34.132528Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:19:11.424599: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:11.792130: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:11.792306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:11.879081: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-15 17:19:11.940833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:11.941038: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:11.941123: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:19.141621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:19.143106: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:19.143548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-03-15 17:19:19.143825: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-03-15 17:19:19.147095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4577 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2023-03-15 17:19:25.644050: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 19200000 exceeds 10% of free system memory.\n",
      "2023-03-15 17:19:26.012590: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 19200000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 17:19:39.701941: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-15 17:19:42.073153: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f18d801a4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-15 17:19:42.088774: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n",
      "2023-03-15 17:19:42.317805: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-15 17:19:43.746911: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-15 17:19:43.992296: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 63s 22ms/step - loss: 1.7584 - acc: 0.4208 - val_loss: 1.1944 - val_acc: 0.4572\n",
      "Epoch 2/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 1.1113 - acc: 0.4559 - val_loss: 1.0532 - val_acc: 0.4787\n",
      "Epoch 3/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0590 - acc: 0.4553 - val_loss: 1.0379 - val_acc: 0.4796\n",
      "Epoch 4/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0497 - acc: 0.4550 - val_loss: 1.0396 - val_acc: 0.4804\n",
      "Epoch 5/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 1.0453 - acc: 0.4566 - val_loss: 1.0294 - val_acc: 0.4827\n",
      "Epoch 6/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 1.0423 - acc: 0.4575 - val_loss: 1.0270 - val_acc: 0.4824\n",
      "Epoch 7/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0409 - acc: 0.4579 - val_loss: 1.0283 - val_acc: 0.4835\n",
      "Epoch 8/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0393 - acc: 0.4572 - val_loss: 1.0251 - val_acc: 0.4835\n",
      "Epoch 9/200\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 1.0383 - acc: 0.4589 - val_loss: 1.0231 - val_acc: 0.4826\n",
      "Epoch 10/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0379 - acc: 0.4574 - val_loss: 1.0220 - val_acc: 0.4829\n",
      "Epoch 11/200\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 1.0355 - acc: 0.4573 - val_loss: 1.0206 - val_acc: 0.4702\n",
      "Epoch 12/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0354 - acc: 0.4593 - val_loss: 1.0197 - val_acc: 0.4832\n",
      "Epoch 13/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0349 - acc: 0.4566 - val_loss: 1.0218 - val_acc: 0.4833\n",
      "Epoch 14/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0342 - acc: 0.4590 - val_loss: 1.0216 - val_acc: 0.4835\n",
      "Epoch 15/200\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 1.0335 - acc: 0.4575 - val_loss: 1.0230 - val_acc: 0.4840\n",
      "Epoch 16/200\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.0331 - acc: 0.4583 - val_loss: 1.0200 - val_acc: 0.4844\n",
      "Epoch 17/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0335 - acc: 0.4586 - val_loss: 1.0178 - val_acc: 0.4828\n",
      "Epoch 18/200\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 1.0325 - acc: 0.4590 - val_loss: 1.0206 - val_acc: 0.4697\n",
      "Epoch 19/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0327 - acc: 0.4586 - val_loss: 1.0190 - val_acc: 0.4836\n",
      "Epoch 20/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0318 - acc: 0.4591 - val_loss: 1.0165 - val_acc: 0.4841\n",
      "Epoch 21/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0316 - acc: 0.4574 - val_loss: 1.0174 - val_acc: 0.4821\n",
      "Epoch 22/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0314 - acc: 0.4586 - val_loss: 1.0161 - val_acc: 0.4839\n",
      "Epoch 23/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0308 - acc: 0.4591 - val_loss: 1.0175 - val_acc: 0.4841\n",
      "Epoch 24/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 1.0312 - acc: 0.4578 - val_loss: 1.0164 - val_acc: 0.4841\n",
      "Epoch 25/200\n",
      "1875/1875 [==============================] - 40s 22ms/step - loss: 1.0305 - acc: 0.4591 - val_loss: 1.0194 - val_acc: 0.4718\n",
      "Epoch 26/200\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.0300 - acc: 0.4610 - val_loss: 1.0176 - val_acc: 0.4731\n",
      "Epoch 27/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0299 - acc: 0.4579 - val_loss: 1.0171 - val_acc: 0.4670\n",
      "Epoch 28/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 1.0301 - acc: 0.4586 - val_loss: 1.0160 - val_acc: 0.4843\n",
      "Epoch 29/200\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 1.0296 - acc: 0.4600 - val_loss: 1.0148 - val_acc: 0.4758\n",
      "Epoch 30/200\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.0294 - acc: 0.4588 - val_loss: 1.0155 - val_acc: 0.4643\n",
      "Epoch 31/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 1.0293 - acc: 0.4588 - val_loss: 1.0166 - val_acc: 0.4833\n",
      "Epoch 32/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0295 - acc: 0.4605 - val_loss: 1.0155 - val_acc: 0.4837\n",
      "Epoch 33/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0297 - acc: 0.4608 - val_loss: 1.0149 - val_acc: 0.4843\n",
      "Epoch 34/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 1.0292 - acc: 0.4597 - val_loss: 1.0191 - val_acc: 0.4702\n",
      "Epoch 35/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0293 - acc: 0.4591 - val_loss: 1.0143 - val_acc: 0.4744\n",
      "Epoch 36/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 1.0292 - acc: 0.4572 - val_loss: 1.0139 - val_acc: 0.4733\n",
      "Epoch 37/200\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.0285 - acc: 0.4594 - val_loss: 1.0142 - val_acc: 0.4697\n",
      "Epoch 38/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 1.0289 - acc: 0.4575 - val_loss: 1.0137 - val_acc: 0.4757\n",
      "Epoch 39/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 1.0283 - acc: 0.4588 - val_loss: 1.0150 - val_acc: 0.4667\n",
      "Epoch 40/200\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 1.0282 - acc: 0.4588 - val_loss: 1.0158 - val_acc: 0.4623\n",
      "Epoch 41/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0278 - acc: 0.4587 - val_loss: 1.0155 - val_acc: 0.4649\n",
      "Epoch 42/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0279 - acc: 0.4601 - val_loss: 1.0145 - val_acc: 0.4709\n",
      "Epoch 43/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0284 - acc: 0.4603 - val_loss: 1.0135 - val_acc: 0.4688\n",
      "Epoch 44/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 1.0281 - acc: 0.4586 - val_loss: 1.0142 - val_acc: 0.4687\n",
      "Epoch 45/200\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 1.0280 - acc: 0.4592 - val_loss: 1.0133 - val_acc: 0.4708\n",
      "Epoch 46/200\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 1.0275 - acc: 0.4586 - val_loss: 1.0142 - val_acc: 0.4721\n",
      "Epoch 47/200\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.0278 - acc: 0.4594 - val_loss: 1.0125 - val_acc: 0.4775\n",
      "Epoch 48/200\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 1.0280 - acc: 0.4595 - val_loss: 1.0134 - val_acc: 0.4836\n",
      "Epoch 49/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 1.0276 - acc: 0.4593 - val_loss: 1.0125 - val_acc: 0.4705\n",
      "Epoch 50/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0271 - acc: 0.4593 - val_loss: 1.0128 - val_acc: 0.4711\n",
      "Epoch 51/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0273 - acc: 0.4592 - val_loss: 1.0121 - val_acc: 0.4699\n",
      "Epoch 52/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0276 - acc: 0.4593 - val_loss: 1.0137 - val_acc: 0.4724\n",
      "Epoch 53/200\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 1.0273 - acc: 0.4604 - val_loss: 1.0126 - val_acc: 0.4727\n",
      "Epoch 54/200\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 1.0271 - acc: 0.4606 - val_loss: 1.0127 - val_acc: 0.4709\n",
      "Epoch 55/200\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 1.0269 - acc: 0.4590 - val_loss: 1.0154 - val_acc: 0.4697\n",
      "Epoch 56/200\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 1.0266 - acc: 0.4598 - val_loss: 1.0138 - val_acc: 0.4682\n",
      "Epoch 57/200\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 1.0264 - acc: 0.4602"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m\n\u001b[1;32m     34\u001b[0m model_checkpoint_callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     35\u001b[0m     filepath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmodel_weights/Model_\u001b[39m\u001b[39m{epoch:02d}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{val_loss:.4f}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{val_acc:0.4f}\u001b[39;00m\u001b[39m.hdf5\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     36\u001b[0m     save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     37\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     38\u001b[0m     mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     39\u001b[0m     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m early_stop \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[1;32m     42\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m     patience\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     start_from_epoch\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m     49\u001b[0m )\n\u001b[0;32m---> 51\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     52\u001b[0m     X_train_robust[:, \u001b[39m-\u001b[39;49mseq_len:, :], y_train,\n\u001b[1;32m     53\u001b[0m     validation_data \u001b[39m=\u001b[39;49m (X_validation_robust[:, \u001b[39m-\u001b[39;49mseq_len:, :], y_validation),\n\u001b[1;32m     54\u001b[0m     batch_size\u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m,\n\u001b[1;32m     55\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m,\n\u001b[1;32m     56\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[model_checkpoint_callback, early_stop]\n\u001b[1;32m     57\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1706\u001b[0m )\n\u001b[1;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m }\n\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2040\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   2037\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   2038\u001b[0m ):\n\u001b[1;32m   2039\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2040\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   2041\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   2042\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(X_train_robust[:, -seq_len:, :].shape[1:])\n",
    "x = tf.keras.layers.Dense(32, activation = \"tanh\", kernel_regularizer = tf.keras.regularizers.L2(0.01))(inputs )\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "h = tf.keras.layers.LSTM(64, return_sequences= True, dropout= 0.4)(x)\n",
    "alpha = TemporalAttentionLayer(units = 64)(h)\n",
    "x = LatentLayer()([alpha,h])\n",
    "x = tf.keras.layers.Dense(32, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.L2(0.01))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(32, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.L2(0.01))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(32, activation = \"relu\", kernel_regularizer = tf.keras.regularizers.L2(0.01))(x)\n",
    "x = tf.keras.layers.Dropout(0.3)(x)\n",
    "output = tf.keras.layers.Dense(3, activation = \"softmax\")(x)\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Model(inputs = inputs, outputs = output)\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = 1E-4),\n",
    "    loss= \"categorical_crossentropy\",\n",
    "    metrics =[\"acc\"]\n",
    ")\n",
    "\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"model_weights/Model_{epoch:02d}-{val_loss:.4f}-{val_acc:0.4f}.hdf5\",\n",
    "    save_weights_only=False,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=12,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,\n",
    "    start_from_epoch=0,\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_robust[:, -seq_len:, :], y_train,\n",
    "    validation_data = (X_validation_robust[:, -seq_len:, :], y_validation),\n",
    "    batch_size= 64,\n",
    "    epochs = 200,\n",
    "    callbacks=[model_checkpoint_callback, early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(885799, 53, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_robust = tranformer_robust.transform(X_test)[:, :, np.newaxis]\n",
    "X_test_robust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "new_model = tf.keras.models.load_model('model_weights/Model_16-1.0200-0.4844.hdf5', \n",
    "    custom_objects={\n",
    "        'TemporalAttentionLayer': TemporalAttentionLayer,\n",
    "        'LatentLayer':LatentLayer\n",
    "    })\n",
    "X_test_robust = tranformer_robust.transform(X_test)[:, :, np.newaxis]\n",
    "results = new_model.predict(X_test_robust[:, -seq_len:, :], batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-14T14:59:30.893310Z",
     "iopub.status.idle": "2023-03-14T14:59:30.893638Z",
     "shell.execute_reply": "2023-03-14T14:59:30.893471Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.893455Z"
    }
   },
   "outputs": [],
   "source": [
    "x_test_df[\"reod\"] = results.argmax(axis=-1) -1\n",
    "result_df = x_test_df[[\"reod\"]]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-14T14:59:30.894557Z",
     "iopub.status.idle": "2023-03-14T14:59:30.894850Z",
     "shell.execute_reply": "2023-03-14T14:59:30.894721Z",
     "shell.execute_reply.started": "2023-03-14T14:59:30.894706Z"
    }
   },
   "outputs": [],
   "source": [
    "result_df.to_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"y_test.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
